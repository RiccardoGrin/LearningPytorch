{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3  3\n",
      " 3  3\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f80976f04e0>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn) # y has grad fn, because it was created through the addition with x\n",
    "print(x.grad_fn) # x does not have grad fn as its the original value\n",
    "\n",
    "# the type shows Backward of type add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 27  27\n",
      " 27  27\n",
      "[torch.FloatTensor of size 2x2]\n",
      " Variable containing:\n",
      " 27\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MulBackward0 object at 0x7f80f40515f8>\n"
     ]
    }
   ],
   "source": [
    "print(z.grad_fn)\n",
    "# the type shows Backward of type multiply, as it was created through multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.5000  4.5000\n",
      " 4.5000  4.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "\n",
    "# 4.5 comes from doing the backprop of 3(x+2)^2, which is the combination of equations to reach z. \n",
    "# If the partical derivation is taken in terms of x, then if becomes (3/2)*(x+2), where x=1 at the start => 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.9988\n",
      "-0.0985\n",
      "-2.0123\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 1.9976\n",
      "-0.1970\n",
      "-4.0247\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 3.9951\n",
      "-0.3940\n",
      "-8.0493\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "  7.9902\n",
      " -0.7881\n",
      "-16.0987\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 15.9805\n",
      " -1.5761\n",
      "-32.1974\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 31.9610\n",
      " -3.1522\n",
      "-64.3947\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "  63.9220\n",
      "  -6.3045\n",
      "-128.7895\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 127.8440\n",
      " -12.6090\n",
      "-257.5789\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 255.6880\n",
      " -25.2179\n",
      "-515.1578\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "  511.3760\n",
      "  -50.4359\n",
      "-1030.3157\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "  511.3760\n",
      "  -50.4359\n",
      "-1030.3157\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad=True)\n",
    "\n",
    "# changed this a bit to try and see what was happening. I feel stupid now, because its so obvious :/\n",
    "y = x * 2  # chenged it to y = (x*0 + 1) * 2, to make easy sense\n",
    "print(y)\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "    print(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "  102.4000\n",
      " 1024.0000\n",
      "    0.1024\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients)\n",
    "\n",
    "print(x.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
